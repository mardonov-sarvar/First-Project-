{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca62cc2-4f35-4e1e-b83c-c9fd000f0fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API sahifa 1 → hozircha 11 ta vacancy\n",
      "API sahifa 2 → hozircha 18 ta vacancy\n",
      "API sahifa 3 → hozircha 27 ta vacancy\n",
      "API sahifa 4 → hozircha 32 ta vacancy\n",
      "API sahifa 5 → hozircha 36 ta vacancy\n",
      "API sahifa 6 → hozircha 39 ta vacancy\n",
      "API sahifa 7 → hozircha 42 ta vacancy\n",
      "API sahifa 8 → hozircha 45 ta vacancy\n",
      "API sahifa 9 → hozircha 49 ta vacancy\n",
      "API sahifa 10 → hozircha 51 ta vacancy\n",
      "API sahifa 11 → hozircha 55 ta vacancy\n",
      "API sahifa 12 → hozircha 58 ta vacancy\n",
      "API sahifa 13 → hozircha 61 ta vacancy\n",
      "API sahifa 14 → hozircha 65 ta vacancy\n",
      "API sahifa 15 → hozircha 68 ta vacancy\n",
      "API sahifa 16 → hozircha 70 ta vacancy\n",
      "API sahifa 17 → hozircha 71 ta vacancy\n",
      "API sahifa 18 → hozircha 75 ta vacancy\n",
      "API sahifa 19 → hozircha 76 ta vacancy\n",
      "API sahifa 20 → hozircha 79 ta vacancy\n",
      "API orqali jami vacancy: 79\n"
     ]
    }
   ],
   "source": [
    "import requests, time, pandas as pd\n",
    "\n",
    "def fetch_api_tashkent(max_pages=20):\n",
    "    url = \"https://api.hh.ru/vacancies\"\n",
    "    headers = {\"accept-language\": \"ru\"}\n",
    "    rows = []\n",
    "    for page in range(max_pages):\n",
    "        params = {\"area\": 2562, \"per_page\": 50, \"page\": page}\n",
    "        r = requests.get(url, params=params, headers=headers)\n",
    "        data = r.json()\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            break\n",
    "        for it in items:\n",
    "            area = it.get(\"area\") or {}\n",
    "            if str(area.get(\"id\")) != \"2562\" and area.get(\"name\") != \"Ташкент\":\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"h_id\": it.get(\"id\"),\n",
    "                \"title\": it.get(\"name\"),\n",
    "                \"company\": (it.get(\"employer\") or {}).get(\"name\"),\n",
    "                \"city\": area.get(\"name\"),\n",
    "                \"salary_from\": (it.get(\"salary\") or {}).get(\"from\"),\n",
    "                \"salary_to\": (it.get(\"salary\") or {}).get(\"to\"),\n",
    "                \"currency\": (it.get(\"salary\") or {}).get(\"currency\"),\n",
    "                \"published_at\": it.get(\"published_at\"),\n",
    "                \"link\": it.get(\"alternate_url\"),\n",
    "                \"source\": \"API\"\n",
    "            })\n",
    "        print(f\"API sahifa {page+1} → hozircha {len(rows)} ta vacancy\")\n",
    "        time.sleep(0.4)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_api = fetch_api_tashkent(max_pages=20)\n",
    "print(\"API orqali jami vacancy:\", len(df_api))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bbea44-001e-4968-8fef-0274432c5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sahifa 1 → 50 ta vacancy topildi\n",
      "Sahifa 2 → 50 ta vacancy topildi\n",
      "Sahifa 3 → 50 ta vacancy topildi\n",
      "Sahifa 4 → 50 ta vacancy topildi\n",
      "Sahifa 5 → 50 ta vacancy topildi\n",
      "Sahifa 6 → 50 ta vacancy topildi\n",
      "Sahifa 7 → 50 ta vacancy topildi\n",
      "Sahifa 8 → 50 ta vacancy topildi\n",
      "Sahifa 9 → 50 ta vacancy topildi\n",
      "Sahifa 10 → 50 ta vacancy topildi\n",
      "Scraping orqali jami vacancy: 500\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_scraping_tashkent(pages=10, headless=True):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    rows = []\n",
    "\n",
    "    for page in range(pages):\n",
    "        url = f\"https://hh.uz/search/vacancy?area=2562&page={page}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Sahifa to‘liq yuklanishini kutish\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[data-qa='serp-item__title']\"))\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Sahifa {page+1} → vacancy yuklanmadi\")\n",
    "            continue\n",
    "\n",
    "        vacancy_links = driver.find_elements(By.CSS_SELECTOR, \"a[data-qa='serp-item__title']\")\n",
    "        for a in vacancy_links:\n",
    "            rows.append({\n",
    "                \"h_id\": None,\n",
    "                \"title\": a.text.strip(),\n",
    "                \"company\": None,\n",
    "                \"city\": \"Ташкент\",  # default, area=2562 bo‘lganligi uchun\n",
    "                \"salary_from\": None,\n",
    "                \"salary_to\": None,\n",
    "                \"currency\": None,\n",
    "                \"published_at\": None,\n",
    "                \"link\": a.get_attribute(\"href\"),\n",
    "                \"source\": \"Scraping\"\n",
    "            })\n",
    "\n",
    "        print(f\"Sahifa {page+1} → {len(vacancy_links)} ta vacancy topildi\")\n",
    "        time.sleep(1)  # sahifalar orasida kichik pauza\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Test\n",
    "df_scraping = fetch_scraping_tashkent(pages=10, headless=True)\n",
    "print(\"Scraping orqali jami vacancy:\", len(df_scraping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a9cef4-a18a-4daf-950b-b30c7b522ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umumiy yig‘ilgan vacancy soni: 546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10236\\314544859.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat([df_api, df_scraping], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.concat([df_api, df_scraping], ignore_index=True)\n",
    "\n",
    "# published_at ustunini datetime formatga o'tkazish\n",
    "df_all[\"published_at\"] = pd.to_datetime(df_all[\"published_at\"], errors=\"coerce\")\n",
    "\n",
    "# Noyob vacancy qoldirish (h_id mavjud bo'lsa h_id asosida, aks holda link)\n",
    "df_all[\"uniq_key\"] = df_all[\"h_id\"].fillna(df_all[\"link\"])\n",
    "df_all = df_all.drop_duplicates(subset=[\"uniq_key\"]).drop(columns=[\"uniq_key\"])\n",
    "\n",
    "print(\"Umumiy yig‘ilgan vacancy soni:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3247400a-0ced-4f87-a6dd-265247746667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Toza Toshkent dataset bazaga yozildi. Count: 546\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# salary ustunini yaratish\n",
    "df_all['salary'] = df_all['salary_from'].combine_first(df_all['salary_to'])\n",
    "\n",
    "# SQL ulanish\n",
    "conn = pyodbc.connect('Driver={SQL Server};Server=WIN-ENG5O096M48;Database=headhunter1;Trusted_Connection=yes')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Jadvalni tozalash\n",
    "cursor.execute(\"TRUNCATE TABLE Vacancyy;\")\n",
    "conn.commit()\n",
    "\n",
    "# Ma’lumotlarni tayyorlash\n",
    "rows_to_insert = [\n",
    "    (\n",
    "        r['title'],\n",
    "        r['company'],\n",
    "        r['city'],\n",
    "        r['salary'] if pd.notnull(r['salary']) else None,\n",
    "        r['currency'] if pd.notnull(r['currency']) else None,\n",
    "        r['published_at'].to_pydatetime() if pd.notnull(r['published_at']) else None,\n",
    "        r['link'],\n",
    "        r['source']\n",
    "    )\n",
    "    for _, r in df_all.iterrows()\n",
    "]\n",
    "\n",
    "# Yozish\n",
    "cursor.fast_executemany = True\n",
    "cursor.executemany(\"\"\"\n",
    "    INSERT INTO Vacancyy (title, company, city, salary, currency, published_at, link, source)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\", rows_to_insert)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Toza Toshkent dataset bazaga yozildi. Count:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4a43a-db5b-4edb-9998-e95f4974be43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bafe26-6b4b-4c57-b7be-76c83af91a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe13ec4-5b5a-4e47-94b8-1a3b961868c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
